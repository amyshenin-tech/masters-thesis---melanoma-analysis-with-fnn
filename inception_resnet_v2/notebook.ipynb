{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rozpoznanie czerniaka na obrazku za pomocą modelu Inception ResNet V2 z Tensorflow Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importujemy biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-21T09:03:15.686440Z",
     "iopub.status.busy": "2021-02-21T09:03:15.684955Z",
     "iopub.status.idle": "2021-02-21T09:03:18.747437Z",
     "shell.execute_reply": "2021-02-21T09:03:18.748436Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ładujemy obrazy treningowe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-21T09:03:18.755230Z",
     "iopub.status.busy": "2021-02-21T09:03:18.754043Z",
     "iopub.status.idle": "2021-02-21T09:03:19.546490Z",
     "shell.execute_reply": "2021-02-21T09:03:19.547461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17732 images belonging to 2 classes.\n",
      "Found 4432 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.2)\n",
    "training_set = datagen.flow_from_directory('../gallery',\n",
    "                                           target_size=(224, 224),\n",
    "                                           batch_size=32,\n",
    "                                           class_mode='binary',\n",
    "                                           subset='training')\n",
    "validation_set = datagen.flow_from_directory('../gallery',\n",
    "                                           target_size=(224, 224),\n",
    "                                           batch_size=32,\n",
    "                                           class_mode='binary',\n",
    "                                           subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ładujemy model MobileNetV2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-21T09:03:19.553345Z",
     "iopub.status.busy": "2021-02-21T09:03:19.552153Z",
     "iopub.status.idle": "2021-02-21T09:03:24.315270Z",
     "shell.execute_reply": "2021-02-21T09:03:24.314286Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/imagenet/inception_resnet_v2/feature_vector/4\", \n",
    "                   input_shape=(224, 224, 3), \n",
    "                   trainable=False),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-21T09:03:24.324444Z",
     "iopub.status.busy": "2021-02-21T09:03:24.319104Z",
     "iopub.status.idle": "2021-02-21T09:03:24.329599Z",
     "shell.execute_reply": "2021-02-21T09:03:24.329108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 1001)              3540265   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 1002      \n",
      "=================================================================\n",
      "Total params: 3,541,267\n",
      "Trainable params: 1,002\n",
      "Non-trainable params: 3,540,265\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kompilujemy poprzednio zbudowany model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-21T09:03:24.342215Z",
     "iopub.status.busy": "2021-02-21T09:03:24.341094Z",
     "iopub.status.idle": "2021-02-21T09:03:24.351054Z",
     "shell.execute_reply": "2021-02-21T09:03:24.349978Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzymy odwołanie (ang. callback) do Tensorboard, żeby zebrać metryki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-21T09:03:24.356082Z",
     "iopub.status.busy": "2021-02-21T09:03:24.355492Z",
     "iopub.status.idle": "2021-02-21T09:03:24.602114Z",
     "shell.execute_reply": "2021-02-21T09:03:24.603072Z"
    }
   },
   "outputs": [],
   "source": [
    "log_dir = '../logs/fit/' + datetime.datetime.now().strftime('transfer---%Y%m%d-%H%M%S')\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzymy odwołanie (ang. callback), które będzie zapisywać model w trakcie trenowania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-21T09:03:24.611520Z",
     "iopub.status.busy": "2021-02-21T09:03:24.610203Z",
     "iopub.status.idle": "2021-02-21T09:03:24.613355Z",
     "shell.execute_reply": "2021-02-21T09:03:24.612838Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = 'checkpoints/simple-{epoch:04d}.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_weights_only=False,\n",
    "    save_freq='epoch',\n",
    "    mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzymy odwołanie (ang. callback), które zatrzyma trenowanie, jeśli nie będzie progresu co najmniej 10 epoch z rzędu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-21T09:03:24.618128Z",
     "iopub.status.busy": "2021-02-21T09:03:24.617415Z",
     "iopub.status.idle": "2021-02-21T09:03:24.619759Z",
     "shell.execute_reply": "2021-02-21T09:03:24.619211Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.01, patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenujemy sieć model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-21T09:03:24.623883Z",
     "iopub.status.busy": "2021-02-21T09:03:24.623297Z",
     "iopub.status.idle": "2021-02-21T15:29:28.511010Z",
     "shell.execute_reply": "2021-02-21T15:29:28.509685Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "555/555 [==============================] - 1928s 3s/step - loss: 0.2846 - accuracy: 0.8849 - val_loss: 0.2285 - val_accuracy: 0.9077\n",
      "\n",
      "Epoch 00001: saving model to checkpoints/simple-0001.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0001.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/simple-0001.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      "555/555 [==============================] - 1928s 3s/step - loss: 0.2369 - accuracy: 0.8996 - val_loss: 0.1769 - val_accuracy: 0.9215\n",
      "\n",
      "Epoch 00002: saving model to checkpoints/simple-0002.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0002.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/simple-0002.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200\n",
      "555/555 [==============================] - 1926s 3s/step - loss: 0.2215 - accuracy: 0.9069 - val_loss: 0.2081 - val_accuracy: 0.9143\n",
      "\n",
      "Epoch 00003: saving model to checkpoints/simple-0003.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0003.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/simple-0003.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200\n",
      "555/555 [==============================] - 1926s 3s/step - loss: 0.2222 - accuracy: 0.9050 - val_loss: 0.2386 - val_accuracy: 0.9102\n",
      "\n",
      "Epoch 00004: saving model to checkpoints/simple-0004.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0004.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/simple-0004.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200\n",
      "555/555 [==============================] - 1925s 3s/step - loss: 0.2185 - accuracy: 0.9068 - val_loss: 0.2196 - val_accuracy: 0.9129\n",
      "\n",
      "Epoch 00005: saving model to checkpoints/simple-0005.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0005.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/simple-0005.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200\n",
      "555/555 [==============================] - 1927s 3s/step - loss: 0.2161 - accuracy: 0.9112 - val_loss: 0.2187 - val_accuracy: 0.9131\n",
      "\n",
      "Epoch 00006: saving model to checkpoints/simple-0006.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0006.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/simple-0006.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200\n",
      "555/555 [==============================] - 1928s 3s/step - loss: 0.2165 - accuracy: 0.9108 - val_loss: 0.2274 - val_accuracy: 0.9134\n",
      "\n",
      "Epoch 00007: saving model to checkpoints/simple-0007.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0007.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/simple-0007.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200\n",
      "555/555 [==============================] - 1923s 3s/step - loss: 0.2114 - accuracy: 0.9106 - val_loss: 0.2086 - val_accuracy: 0.9143\n",
      "\n",
      "Epoch 00008: saving model to checkpoints/simple-0008.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0008.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/simple-0008.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200\n",
      "555/555 [==============================] - 1925s 3s/step - loss: 0.2122 - accuracy: 0.9148 - val_loss: 0.2198 - val_accuracy: 0.9165\n",
      "\n",
      "Epoch 00009: saving model to checkpoints/simple-0009.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0009.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/simple-0009.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200\n",
      "555/555 [==============================] - 1926s 3s/step - loss: 0.2056 - accuracy: 0.9180 - val_loss: 0.2071 - val_accuracy: 0.9181\n",
      "\n",
      "Epoch 00010: saving model to checkpoints/simple-0010.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0010.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/simple-0010.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200\n",
      "555/555 [==============================] - 1926s 3s/step - loss: 0.2085 - accuracy: 0.9147 - val_loss: 0.2311 - val_accuracy: 0.9120\n",
      "\n",
      "Epoch 00011: saving model to checkpoints/simple-0011.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0011.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/simple-0011.ckpt/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200\n",
      "555/555 [==============================] - 1924s 3s/step - loss: 0.2080 - accuracy: 0.9124 - val_loss: 0.1887 - val_accuracy: 0.9204\n",
      "\n",
      "Epoch 00012: saving model to checkpoints/simple-0012.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0012.ckpt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: checkpoints/simple-0012.ckpt/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4e581a8e80>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(training_set, validation_data=validation_set, epochs=200, callbacks=[tensorboard_callback,\n",
    "                                                                     checkpoint_callback,\n",
    "                                                                     early_stop_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
