{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rozpoznanie czerniaka na obrazku za pomocą prostej sieci konwolucyjnej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importujemy biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T22:40:12.082524Z",
     "iopub.status.busy": "2021-02-18T22:40:12.081027Z",
     "iopub.status.idle": "2021-02-18T22:40:15.828537Z",
     "shell.execute_reply": "2021-02-18T22:40:15.828910Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ładujemy obrazy treningowe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T22:40:15.834101Z",
     "iopub.status.busy": "2021-02-18T22:40:15.833535Z",
     "iopub.status.idle": "2021-02-18T22:40:16.616903Z",
     "shell.execute_reply": "2021-02-18T22:40:16.617281Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17732 images belonging to 2 classes.\n",
      "Found 4432 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.2)\n",
    "training_set = datagen.flow_from_directory('gallery',\n",
    "                                           target_size=(128, 128),\n",
    "                                           batch_size=32,\n",
    "                                           class_mode='binary',\n",
    "                                           subset='training')\n",
    "validation_set = datagen.flow_from_directory('gallery',\n",
    "                                           target_size=(128, 128),\n",
    "                                           batch_size=32,\n",
    "                                           class_mode='binary',\n",
    "                                           subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Budujemy sieć konwolucyjną z 3 warstwami konwolucyjnymi (ang. convolutional layer) i 2 warstwami gęstymi (ang. dense layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T22:40:16.625305Z",
     "iopub.status.busy": "2021-02-18T22:40:16.624400Z",
     "iopub.status.idle": "2021-02-18T22:40:18.229065Z",
     "shell.execute_reply": "2021-02-18T22:40:18.228056Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn = Sequential([\n",
    "    # pierwsza warstwa konwolucyjna\n",
    "    Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPool2D(pool_size=2, strides=2),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # druga warstwa konwolucyjna\n",
    "    Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPool2D(pool_size=2, strides=2),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # trzecia warstwa konwolucyjna\n",
    "    Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPool2D(pool_size=2, strides=2),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # trasformacja macierzy do tablicy (2D -> 1D)\n",
    "    Flatten(),\n",
    "    \n",
    "    # 2 warstwy gęste\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # warstwa wyjściowa\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kompilujemy poprzednio zbudowany model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T22:40:18.241527Z",
     "iopub.status.busy": "2021-02-18T22:40:18.240379Z",
     "iopub.status.idle": "2021-02-18T22:40:18.249552Z",
     "shell.execute_reply": "2021-02-18T22:40:18.250043Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzymy odwołanie (ang. callback) do Tensorboard, żeby zebrać metryki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T22:40:18.255762Z",
     "iopub.status.busy": "2021-02-18T22:40:18.254571Z",
     "iopub.status.idle": "2021-02-18T22:40:18.516404Z",
     "shell.execute_reply": "2021-02-18T22:40:18.517380Z"
    }
   },
   "outputs": [],
   "source": [
    "log_dir = 'logs/fit/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzymy odwołanie (ang. callback), które będzie zapisywać najlepszy model w trakcie trenowania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T22:40:18.523807Z",
     "iopub.status.busy": "2021-02-18T22:40:18.522573Z",
     "iopub.status.idle": "2021-02-18T22:40:18.524732Z",
     "shell.execute_reply": "2021-02-18T22:40:18.525200Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = 'checkpoints/best_simple_cnn.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_weights_only=False,\n",
    "    save_freq='epoch',\n",
    "    mode='auto',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzymy odwołanie (ang. callback), które zatrzyma trenowanie, jeśli nie będzie progresu co najmniej 10 epoch z rzędu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T22:40:18.529181Z",
     "iopub.status.busy": "2021-02-18T22:40:18.528600Z",
     "iopub.status.idle": "2021-02-18T22:40:18.531385Z",
     "shell.execute_reply": "2021-02-18T22:40:18.530771Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1, patience=10, restore_best_weights=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenujemy sieć konwolucyjną."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T22:40:18.535587Z",
     "iopub.status.busy": "2021-02-18T22:40:18.535015Z",
     "iopub.status.idle": "2021-02-19T04:32:43.352391Z",
     "shell.execute_reply": "2021-02-19T04:32:43.359590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "555/555 [==============================] - 1947s 3s/step - loss: 0.3692 - accuracy: 0.8768 - val_loss: 0.2446 - val_accuracy: 0.8849\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.24461, saving model to checkpoints/best_simple_cnn.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/best_simple_cnn.ckpt/assets\n",
      "Epoch 2/200\n",
      "555/555 [==============================] - 1919s 3s/step - loss: 0.2840 - accuracy: 0.8884 - val_loss: 0.2773 - val_accuracy: 0.8858\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.24461\n",
      "Epoch 3/200\n",
      "555/555 [==============================] - 1918s 3s/step - loss: 0.2966 - accuracy: 0.8873 - val_loss: 0.2452 - val_accuracy: 0.8867\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.24461\n",
      "Epoch 4/200\n",
      "555/555 [==============================] - 1919s 3s/step - loss: 0.2786 - accuracy: 0.8865 - val_loss: 0.2501 - val_accuracy: 0.8867\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.24461\n",
      "Epoch 5/200\n",
      "555/555 [==============================] - 1920s 3s/step - loss: 0.2695 - accuracy: 0.8873 - val_loss: 0.2374 - val_accuracy: 0.8876\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.24461 to 0.23742, saving model to checkpoints/best_simple_cnn.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/best_simple_cnn.ckpt/assets\n",
      "Epoch 6/200\n",
      "555/555 [==============================] - 1920s 3s/step - loss: 0.2573 - accuracy: 0.8909 - val_loss: 0.2764 - val_accuracy: 0.8867\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.23742\n",
      "Epoch 7/200\n",
      "555/555 [==============================] - 1915s 3s/step - loss: 0.2510 - accuracy: 0.8943 - val_loss: 0.2163 - val_accuracy: 0.8865\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.23742 to 0.21632, saving model to checkpoints/best_simple_cnn.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/best_simple_cnn.ckpt/assets\n",
      "Epoch 8/200\n",
      "555/555 [==============================] - 1917s 3s/step - loss: 0.2406 - accuracy: 0.9013 - val_loss: 0.2365 - val_accuracy: 0.8903\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.21632\n",
      "Epoch 9/200\n",
      "555/555 [==============================] - 1918s 3s/step - loss: 0.2278 - accuracy: 0.9010 - val_loss: 0.2587 - val_accuracy: 0.8897\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.21632\n",
      "Epoch 10/200\n",
      "555/555 [==============================] - 1924s 3s/step - loss: 0.2243 - accuracy: 0.9047 - val_loss: 0.2432 - val_accuracy: 0.8890\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.21632\n",
      "Epoch 11/200\n",
      "555/555 [==============================] - 1921s 3s/step - loss: 0.2052 - accuracy: 0.9122 - val_loss: 0.2623 - val_accuracy: 0.8892\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.21632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7364d65ef0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(training_set, validation_data=validation_set, epochs=200, callbacks=[tensorboard_callback,\n",
    "                                                                     checkpoint_callback,\n",
    "                                                                     early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
