{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rozpoznanie czerniaka na obrazku za pomocą prostej sieci konwolucyjnej"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importujemy biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T21:45:35.028452Z",
     "iopub.status.busy": "2021-02-20T21:45:35.026884Z",
     "iopub.status.idle": "2021-02-20T21:45:38.996868Z",
     "shell.execute_reply": "2021-02-20T21:45:38.996438Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ładujemy obrazy treningowe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T21:45:39.007619Z",
     "iopub.status.busy": "2021-02-20T21:45:39.006307Z",
     "iopub.status.idle": "2021-02-20T21:45:39.753941Z",
     "shell.execute_reply": "2021-02-20T21:45:39.754839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17732 images belonging to 2 classes.\n",
      "Found 4432 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.2)\n",
    "training_set = datagen.flow_from_directory('../gallery',\n",
    "                                           target_size=(128, 128),\n",
    "                                           batch_size=32,\n",
    "                                           class_mode='binary',\n",
    "                                           subset='training')\n",
    "validation_set = datagen.flow_from_directory('../gallery',\n",
    "                                           target_size=(128, 128),\n",
    "                                           batch_size=32,\n",
    "                                           class_mode='binary',\n",
    "                                           subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Budujemy sieć konwolucyjną z 3 warstwami konwolucyjnymi (ang. convolutional layer) i 2 warstwami gęstymi (ang. dense layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T21:45:39.761947Z",
     "iopub.status.busy": "2021-02-20T21:45:39.761353Z",
     "iopub.status.idle": "2021-02-20T21:45:41.430344Z",
     "shell.execute_reply": "2021-02-20T21:45:41.429277Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn = Sequential([\n",
    "    # pierwsza warstwa konwolucyjna\n",
    "    Conv2D(filters=64, kernel_size=3, activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPool2D(pool_size=2, strides=2),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # druga warstwa konwolucyjna\n",
    "    Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPool2D(pool_size=2, strides=2),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # trzecia warstwa konwolucyjna\n",
    "    Conv2D(filters=64, kernel_size=3, activation='relu'),\n",
    "    MaxPool2D(pool_size=2, strides=2),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # trasformacja macierzy do tablicy (2D -> 1D)\n",
    "    Flatten(),\n",
    "    \n",
    "    # 2 warstwy gęste\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # warstwa wyjściowa\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kompilujemy poprzednio zbudowany model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T21:45:41.445923Z",
     "iopub.status.busy": "2021-02-20T21:45:41.444748Z",
     "iopub.status.idle": "2021-02-20T21:45:41.452911Z",
     "shell.execute_reply": "2021-02-20T21:45:41.453840Z"
    }
   },
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzymy odwołanie (ang. callback) do Tensorboard, żeby zebrać metryki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T21:45:41.458414Z",
     "iopub.status.busy": "2021-02-20T21:45:41.457816Z",
     "iopub.status.idle": "2021-02-20T21:45:41.726940Z",
     "shell.execute_reply": "2021-02-20T21:45:41.725941Z"
    }
   },
   "outputs": [],
   "source": [
    "log_dir = '../logs/fit/' + datetime.datetime.now().strftime('simple---%Y%m%d-%H%M%S')\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzymy odwołanie (ang. callback), które będzie zapisywać najlepszy model w trakcie trenowania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T21:45:41.733546Z",
     "iopub.status.busy": "2021-02-20T21:45:41.732369Z",
     "iopub.status.idle": "2021-02-20T21:45:41.734784Z",
     "shell.execute_reply": "2021-02-20T21:45:41.735750Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = 'checkpoints/simple-{epoch:04d}.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_weights_only=False,\n",
    "    save_freq='epoch',\n",
    "    mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tworzymy odwołanie (ang. callback), które zatrzyma trenowanie, jeśli nie będzie progresu co najmniej 10 epoch z rzędu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T21:45:41.740253Z",
     "iopub.status.busy": "2021-02-20T21:45:41.739682Z",
     "iopub.status.idle": "2021-02-20T21:45:41.742718Z",
     "shell.execute_reply": "2021-02-20T21:45:41.742203Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=0.01, patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trenujemy sieć konwolucyjną."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-20T21:45:41.746929Z",
     "iopub.status.busy": "2021-02-20T21:45:41.746363Z",
     "iopub.status.idle": "2021-02-21T06:49:13.866988Z",
     "shell.execute_reply": "2021-02-21T06:49:13.872112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "555/555 [==============================] - 1944s 3s/step - loss: 0.3473 - accuracy: 0.8834 - val_loss: 0.2476 - val_accuracy: 0.8865\n",
      "\n",
      "Epoch 00001: saving model to checkpoints/simple-0001.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0001.ckpt/assets\n",
      "Epoch 2/200\n",
      "555/555 [==============================] - 1915s 3s/step - loss: 0.2940 - accuracy: 0.8858 - val_loss: 0.2454 - val_accuracy: 0.8872\n",
      "\n",
      "Epoch 00002: saving model to checkpoints/simple-0002.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0002.ckpt/assets\n",
      "Epoch 3/200\n",
      "555/555 [==============================] - 1917s 3s/step - loss: 0.2823 - accuracy: 0.8870 - val_loss: 0.2336 - val_accuracy: 0.8858\n",
      "\n",
      "Epoch 00003: saving model to checkpoints/simple-0003.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0003.ckpt/assets\n",
      "Epoch 4/200\n",
      "555/555 [==============================] - 1916s 3s/step - loss: 0.2597 - accuracy: 0.8902 - val_loss: 0.2985 - val_accuracy: 0.8858\n",
      "\n",
      "Epoch 00004: saving model to checkpoints/simple-0004.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0004.ckpt/assets\n",
      "Epoch 5/200\n",
      "555/555 [==============================] - 1914s 3s/step - loss: 0.2698 - accuracy: 0.8880 - val_loss: 0.2557 - val_accuracy: 0.8892\n",
      "\n",
      "Epoch 00005: saving model to checkpoints/simple-0005.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0005.ckpt/assets\n",
      "Epoch 6/200\n",
      "555/555 [==============================] - 1912s 3s/step - loss: 0.2657 - accuracy: 0.8879 - val_loss: 0.2257 - val_accuracy: 0.8876\n",
      "\n",
      "Epoch 00006: saving model to checkpoints/simple-0006.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0006.ckpt/assets\n",
      "Epoch 7/200\n",
      "555/555 [==============================] - 1915s 3s/step - loss: 0.2584 - accuracy: 0.8891 - val_loss: 0.2060 - val_accuracy: 0.8879\n",
      "\n",
      "Epoch 00007: saving model to checkpoints/simple-0007.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0007.ckpt/assets\n",
      "Epoch 8/200\n",
      "555/555 [==============================] - 1915s 3s/step - loss: 0.2529 - accuracy: 0.8867 - val_loss: 0.2467 - val_accuracy: 0.8885\n",
      "\n",
      "Epoch 00008: saving model to checkpoints/simple-0008.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0008.ckpt/assets\n",
      "Epoch 9/200\n",
      "555/555 [==============================] - 1914s 3s/step - loss: 0.2461 - accuracy: 0.8946 - val_loss: 0.3329 - val_accuracy: 0.8888\n",
      "\n",
      "Epoch 00009: saving model to checkpoints/simple-0009.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0009.ckpt/assets\n",
      "Epoch 10/200\n",
      "555/555 [==============================] - 1917s 3s/step - loss: 0.2268 - accuracy: 0.8981 - val_loss: 0.2123 - val_accuracy: 0.8919\n",
      "\n",
      "Epoch 00010: saving model to checkpoints/simple-0010.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0010.ckpt/assets\n",
      "Epoch 11/200\n",
      "555/555 [==============================] - 1915s 3s/step - loss: 0.2288 - accuracy: 0.9037 - val_loss: 0.2790 - val_accuracy: 0.8876\n",
      "\n",
      "Epoch 00011: saving model to checkpoints/simple-0011.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0011.ckpt/assets\n",
      "Epoch 12/200\n",
      "555/555 [==============================] - 1917s 3s/step - loss: 0.2227 - accuracy: 0.9066 - val_loss: 0.2328 - val_accuracy: 0.8912\n",
      "\n",
      "Epoch 00012: saving model to checkpoints/simple-0012.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0012.ckpt/assets\n",
      "Epoch 13/200\n",
      "555/555 [==============================] - 1913s 3s/step - loss: 0.2136 - accuracy: 0.9124 - val_loss: 0.2516 - val_accuracy: 0.8915\n",
      "\n",
      "Epoch 00013: saving model to checkpoints/simple-0013.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0013.ckpt/assets\n",
      "Epoch 14/200\n",
      "555/555 [==============================] - 1914s 3s/step - loss: 0.2074 - accuracy: 0.9086 - val_loss: 0.2824 - val_accuracy: 0.8897\n",
      "\n",
      "Epoch 00014: saving model to checkpoints/simple-0014.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0014.ckpt/assets\n",
      "Epoch 15/200\n",
      "555/555 [==============================] - 1915s 3s/step - loss: 0.1986 - accuracy: 0.9183 - val_loss: 0.2420 - val_accuracy: 0.8915\n",
      "\n",
      "Epoch 00015: saving model to checkpoints/simple-0015.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0015.ckpt/assets\n",
      "Epoch 16/200\n",
      "555/555 [==============================] - 1917s 3s/step - loss: 0.1803 - accuracy: 0.9265 - val_loss: 0.2357 - val_accuracy: 0.8960\n",
      "\n",
      "Epoch 00016: saving model to checkpoints/simple-0016.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0016.ckpt/assets\n",
      "Epoch 17/200\n",
      "555/555 [==============================] - 1918s 3s/step - loss: 0.1848 - accuracy: 0.9246 - val_loss: 0.2690 - val_accuracy: 0.8906\n",
      "\n",
      "Epoch 00017: saving model to checkpoints/simple-0017.ckpt\n",
      "INFO:tensorflow:Assets written to: checkpoints/simple-0017.ckpt/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f11c9325da0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(training_set, validation_data=validation_set, epochs=200, callbacks=[tensorboard_callback,\n",
    "                                                                     checkpoint_callback,\n",
    "                                                                     early_stop_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
